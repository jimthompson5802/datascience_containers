{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Larger CNN for the MNIST Dataset\n",
    "import numpy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1).astype('float32')\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 22s - loss: 0.3991 - acc: 0.8742 - val_loss: 0.0753 - val_acc: 0.9756\n",
      "Epoch 2/10\n",
      " - 23s - loss: 0.0936 - acc: 0.9715 - val_loss: 0.0454 - val_acc: 0.9857\n",
      "Epoch 3/10\n",
      " - 23s - loss: 0.0645 - acc: 0.9797 - val_loss: 0.0399 - val_acc: 0.9868\n",
      "Epoch 4/10\n",
      " - 22s - loss: 0.0545 - acc: 0.9828 - val_loss: 0.0355 - val_acc: 0.9874\n",
      "Epoch 5/10\n",
      " - 22s - loss: 0.0455 - acc: 0.9853 - val_loss: 0.0310 - val_acc: 0.9898\n",
      "Epoch 6/10\n",
      " - 22s - loss: 0.0413 - acc: 0.9865 - val_loss: 0.0307 - val_acc: 0.9898\n",
      "Epoch 7/10\n",
      " - 22s - loss: 0.0359 - acc: 0.9889 - val_loss: 0.0292 - val_acc: 0.9908\n",
      "Epoch 8/10\n",
      " - 22s - loss: 0.0334 - acc: 0.9893 - val_loss: 0.0355 - val_acc: 0.9885\n",
      "Epoch 9/10\n",
      " - 22s - loss: 0.0311 - acc: 0.9898 - val_loss: 0.0313 - val_acc: 0.9901\n",
      "Epoch 10/10\n",
      " - 22s - loss: 0.0294 - acc: 0.9901 - val_loss: 0.0272 - val_acc: 0.9917\n",
      "Large CNN Error: 0.83%\n"
     ]
    }
   ],
   "source": [
    "# define the larger model\n",
    "def larger_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\tmodel.add(Dropout(0.2))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu'))\n",
    "\tmodel.add(Dense(50, activation='relu'))\n",
    "\tmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200,verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
